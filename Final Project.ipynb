{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wolframalpha\n",
    "import pyttsx3\n",
    "import speech_recognition as sr\n",
    "import datetime\n",
    "import wikipedia\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import os\n",
    "import cv2, time, pandas\n",
    "from datetime import datetime\n",
    "import csv\n",
    "import sys\n",
    "import winsound\n",
    "from selenium import webdriver\n",
    "from csv import reader\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Link Database\n",
    "import mysql.connector\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"db4free.net\",\n",
    "  user=\"shibinthomas\",\n",
    "  password=\"shibint85@\",\n",
    "  database=\"shibinthomas\"\n",
    ")\n",
    "\n",
    "mycursor = mydb.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print Database\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to open Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objdet():\n",
    "    cap = cv2.VideoCapture(0)  # open camera\n",
    "    ret, frame1 = cap.read()\n",
    "    ret, frame2 = cap.read()\n",
    "    while cap.isOpened():\n",
    "        diff = cv2.absdiff(frame1, frame2)\n",
    "        gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "        blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "        _, thresh = cv2.threshold(blur, 20, 255, cv2.THRESH_BINARY)\n",
    "        dilated = cv2.dilate(thresh, None, iterations=3)\n",
    "        contours, _ = cv2.findContours(dilated, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        #cv2.drawContours (frame1, contours, -1, (0,255,0), 2)\n",
    "        for contour in contours:\n",
    "            (x, y, w, h) = cv2.boundingRect(contour)\n",
    "            if cv2.contourArea(contour) < 10000:\n",
    "                continue\n",
    "            cv2.rectangle(frame1, (x, y), (x + y, y + h), (0, 255, 0), 1)\n",
    "            cv2.putText(frame1, \"Status: Movement\", (10, 20), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 1, )\n",
    "            winsound.Beep(2500,50)\n",
    "            #waobjdet()\n",
    "        cv2.imshow(\"feed\", frame1)   \n",
    "        frame1 = frame2\n",
    "        ret, frame2 = cap.read()\n",
    "        key = cv2.waitKey(50)\n",
    "        if key == 27:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bin Bot main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def takeCommand():\n",
    "    r = sr.Recognizer() \n",
    "    with sr.Microphone() as source: \n",
    "        print('Listening...',end=\" \") \n",
    "        r.pause_threshold = 0.7\n",
    "        audio = r.listen(source)\n",
    "        try: \n",
    "            print(\"Recognizing...\") \n",
    "            Query = r.recognize_google(audio, language='en-in') \n",
    "            print(\"Recognized as: \", Query)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"Please be more clear\")\n",
    "            return \"none\"\n",
    "        return Query\n",
    "\n",
    "def speak(audio):\n",
    "    strlen=len(audio.split())\n",
    "    if strlen>=20:\n",
    "        audio=audio.split()[:20]\n",
    "        audio=' '.join(map(str, audio)) \n",
    "    #print(audio)\n",
    "    #waspeak(audio)\n",
    "    engine = pyttsx3.init() \n",
    "    voices = engine.getProperty('voices') \n",
    "    engine.setProperty('voice', voices[0].id) \n",
    "    engine.say(audio) \n",
    "    engine.runAndWait()\n",
    "    \n",
    "def talking_tom():\n",
    "    while(True):\n",
    "        talk=takeCommand().lower()\n",
    "        if \"none\" in talk:\n",
    "            continue\n",
    "        if \"exit\" in talk:\n",
    "            speak(\"Thank you for spending your time with me.\")\n",
    "            bin()\n",
    "            break\n",
    "        speak(talk)\n",
    "\n",
    "def tellDay(): \n",
    "    day = datetime.today().weekday() + 1 \n",
    "    Day_dict = {1: 'Monday', 2: 'Tuesday',3: 'Wednesday', 4: 'Thursday',5: 'Friday', 6: 'Saturday',7: 'Sunday'} \n",
    "    if day in Day_dict.keys(): \n",
    "        day_of_the_week = Day_dict[day] \n",
    "        print(day_of_the_week) \n",
    "        speak(\"The day is \" + day_of_the_week) \n",
    "\n",
    "\n",
    "def tellTime(): \n",
    "    time = str(datetime.now()) \n",
    "    print(time) \n",
    "    hour = time[11:13] \n",
    "    min = time[14:16] \n",
    "    speak(\"The time is sir\" + hour + \"Hours and\" + min + \"Minutes\")\t \n",
    "\n",
    "    \n",
    "def Hello(): \n",
    "    speak(\"hello sir I am your desktop assistant.Tell me how may I help you\") \n",
    "    \n",
    "                \n",
    "def most_frequent(List):\n",
    "    return max(set(List), key = List.count)\n",
    "\n",
    "def bin():\n",
    "    while(True):\n",
    "        query = takeCommand().lower()\n",
    "        if query==\"none\":\n",
    "            continue\n",
    "        elif \"hello\" in query:\n",
    "            Hello()\n",
    "        elif \"bhai\" in query:\n",
    "            speak(\"Thank you i will take a leave\")\n",
    "            Take_query()\n",
    "            break\n",
    "        elif \"bye\" in query:\n",
    "            speak(\"Thank you i will take a leave\")\n",
    "            Take_query()\n",
    "            break\n",
    "        elif \"from wikipedia\" in query: \n",
    "            speak(\"Checking the wikipedia \") \n",
    "            query = query.replace(\"wikipedia\", \"\")  \n",
    "            result = wikipedia.summary(query, sentences=1) \n",
    "            speak(\"According to wikipedia\") \n",
    "            speak(result)\n",
    "        elif \"talking tom\" in query:\n",
    "            speak(\"Loading Talking Tom please wait\")\n",
    "            talking_tom()\n",
    "            break\n",
    "        else:\n",
    "            try:\n",
    "                res=client.query(query)\n",
    "                output=next(res.results).text\n",
    "                speak(output)\n",
    "            except:\n",
    "                speak(\"Please be more clear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attendance Check and append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(name_list):\n",
    "    if len(name_list)%100==0 and most_frequent(name_list)!=\"Unknown\":\n",
    "        std_name=most_frequent(name_list)\n",
    "        print(\"Detected as:\",std_name)\n",
    "        speak('detected as'+std_name)\n",
    "        while True:\n",
    "            check=takeCommand().lower()\n",
    "            if check==\"yes\":   \n",
    "                mycursor.execute(\"SELECT * FROM userpage_userdetails where empId='%s'\" % std_name),\n",
    "                userDet = mycursor.fetchall()\n",
    "                if(len(userDet)>0):\n",
    "                    forKey=userDet[0][0]\n",
    "                else:\n",
    "                    forKey=0\n",
    "                now=datetime.now()\n",
    "                mycursor.execute(\"SELECT * FROM trackingDetails_trackers where empId='%s'\" % std_name),\n",
    "                myresult = mycursor.fetchall()\n",
    "                empLength=len(myresult)\n",
    "                print(empLength)\n",
    "                flag=True\n",
    "                if empLength%2==0:\n",
    "                    flag=True\n",
    "                else:\n",
    "                    flag=False\n",
    "                sql = \"INSERT INTO trackingDetails_trackers (empId,is_active,lastUpdatedBy,forKey) VALUES (%s, %s,%s,%s)\"\n",
    "                val = (std_name,flag,datetime.now(),forKey)\n",
    "                mycursor.execute(sql, val)\n",
    "                mydb.commit()\n",
    "                print(std_name)\n",
    "                #markAttendance(std_name)\n",
    "                print(\"Thank You Next Person please\")\n",
    "                speak(\"Thank You Next Person please\")\n",
    "                name_list.clear()\n",
    "                #wacall(std_name)\n",
    "            elif check=='quit':\n",
    "                name_list.clear()\n",
    "                speak('Exiting Attendance system')\n",
    "                cv2.destroyAllWindows()\n",
    "                Take_query()\n",
    "            elif check==\"no\":\n",
    "                print(\"Please try again\")\n",
    "                name_list.clear()\n",
    "            if check==\"yes\" or check==\"no\" or check==\"quit\":\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face encoding Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Encoding\n",
      "['EMP1', 'EMP2', 'EMP3', 'EMP4']\n"
     ]
    }
   ],
   "source": [
    "path='E:/Projects/Python/Face-Recogntion/photos1'\n",
    "images=[]\n",
    "classNames=[]\n",
    "allList=[]\n",
    "regNo=[]\n",
    "myList=os.listdir(path)\n",
    "for name in myList:\n",
    "    curImg=cv2.imread(f'{path}/{name}')\n",
    "    images.append(curImg)\n",
    "    all=name\n",
    "    name=name.split('_')\n",
    "    reg=name[0]\n",
    "    name=name[1]\n",
    "    regNo.append(os.path.splitext(reg)[0])\n",
    "    classNames.append(os.path.splitext(name)[0])\n",
    "    allList.append(os.path.splitext(all)[0])\n",
    "def findEncodings(images):\n",
    "    encodeList=[]\n",
    "    for img in images:\n",
    "        img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        encode=face_recognition.face_encodings(img)[0]\n",
    "        encodeList.append(encode)\n",
    "    return encodeList\n",
    "\n",
    "\n",
    "encodeListKnown=findEncodings(images)\n",
    "speak(\"Completed Encoding\")\n",
    "print(\"Completed Encoding\")\n",
    "\n",
    "known_face_encodings=encodeListKnown\n",
    "known_face_names=classNames\n",
    "print(known_face_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Recognition Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def face_rec():\n",
    "    # Initialize some variables\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "    face_locations = []\n",
    "    face_encodings = []\n",
    "    face_names = []\n",
    "    process_this_frame = True\n",
    "    # Csv file\n",
    "    df = pandas.DataFrame(columns=[\"Start\", \"End\"])\n",
    "    count=\"Unknown\"\n",
    "    name_list=[]\n",
    "    \n",
    "    while True:\n",
    "        # Grab a single frame of video\n",
    "        ret, frame = video_capture.read()\n",
    "\n",
    "        # Resize frame of video to 1/4 size for faster face recognition processing\n",
    "        small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "\n",
    "        # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
    "        rgb_small_frame = small_frame[:, :, ::-1]\n",
    "        status = 0\n",
    "        # Only process every other frame of video to save time\n",
    "        if process_this_frame:\n",
    "            # Find all the faces and face encodings in the current frame of video\n",
    "            face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "            # face_locations = face_recognition.face_locations(rgb_small_frame, number_of_times_to_upsample=0, model=\"cnn\")\n",
    "            face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "\n",
    "            face_names = []\n",
    "            for face_encoding in face_encodings:\n",
    "                # See if the face is a match for the known face(s)\n",
    "                matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "                name = \"Unknown\"\n",
    "\n",
    "                # # If a match was found in known_face_encodings, just use the first one.\n",
    "                if True in matches:\n",
    "                    first_match_index = matches.index(True)\n",
    "                    name = known_face_names[first_match_index]\n",
    "                #name check\n",
    "                face_names.append(name)                 \n",
    "                if count!=name:\n",
    "                    count=name\n",
    "                    #speak(name)                            #--> To speak the detected name and the change in name\n",
    "\n",
    "        process_this_frame = not process_this_frame\n",
    "\n",
    "        # Display the results\n",
    "        for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "            # Scale back up face locations since the frame we detected in was scaled to 1/4 size\n",
    "            top *= 4\n",
    "            right *= 4\n",
    "            bottom *= 4\n",
    "            left *= 4\n",
    "            status = 1\n",
    "            # Draw a box around the face\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 0), 1)\n",
    "\n",
    "            # Draw a label with a name below the face\n",
    "            cv2.rectangle(\n",
    "                frame, (left, bottom - 35), (right, bottom), (0, 0, 0), cv2.FILLED\n",
    "            )\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "            name_list.append(name)\n",
    "            winsound.Beep(2500,50)\n",
    "            \n",
    "            # Check Function to check whether the person is right and Append to CSV\n",
    "            check(name_list)\n",
    "        # Display the resulting image\n",
    "        cv2.imshow(\"Video\", frame)\n",
    "\n",
    "\n",
    "        # Hit 'q' on the keyboard to quit!\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    # Release handle to the webcam\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main call Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening... "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-9f4ed15f0614>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mTake_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-9f4ed15f0614>\u001b[0m in \u001b[0;36mTake_query\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mTake_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtakeCommand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m\"bin\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0mspeak\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Hello i am bin bot, here to help you\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-500001837197>\u001b[0m in \u001b[0;36mtakeCommand\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Listening...'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpause_threshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.7\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0maudio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlisten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Recognizing...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\miniproject\\lib\\site-packages\\speech_recognition\\__init__.py\u001b[0m in \u001b[0;36mlisten\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[0;32m    650\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 652\u001b[1;33m                 \u001b[0mbuffer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCHUNK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    653\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mbreak\u001b[0m  \u001b[1;31m# reached end of the stream\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m                 \u001b[0mframes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\miniproject\\lib\\site-packages\\speech_recognition\\__init__.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyaudio_stream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\miniproject\\lib\\site-packages\\pyaudio.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    606\u001b[0m                           paCanNotReadFromAnOutputOnlyStream)\n\u001b[0;32m    607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_read_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "client = wolframalpha.Client('7E2K87-L6AH35EQ44')\n",
    "def Take_query(): \n",
    "    while(True):\n",
    "        query = takeCommand().lower()\n",
    "        if \"bin\" in query:\n",
    "            speak(\"Hello i am bin bot, here to help you\")\n",
    "            bin()\n",
    "        elif \"attendance\" in query:\n",
    "            speak(\"Loading attendance\")\n",
    "            face_rec()\n",
    "        elif \"detect\" in query:\n",
    "            speak(\"Loading Object Detection\")\n",
    "            objdet()\n",
    "        elif \"mask\" in query:\n",
    "            speak(\"Loading Mask Detection\")\n",
    "            mask()\n",
    "        elif \"exit\" in query:\n",
    "            speak(\"Turning off Bin bot, Thankyou\")\n",
    "            sys.exit()\n",
    "            break\n",
    "Take_query()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Cheet Sheet</h1>\n",
    "<h3>Sleep mode</h3>\n",
    "\n",
    "1. **Bin** - Go to Bin mode\n",
    "2. **Attendance** - Go to attendance mode\n",
    "3. **detect** - Object Detection\n",
    "4. **exit** - Switch off bin bot\n",
    "\n",
    "<h3>Bin bot</h3>\n",
    "\n",
    "1. **bye** - Go back to Sleep mode\n",
    "2. **from wikipedia** - Search from Wikipedia\n",
    "3. **Talking tom** - Switch to talking tom mode\n",
    "\n",
    "<h3>Attendance</h3>\n",
    "\n",
    "1. **yes** - To append Attendance\n",
    "2. **no** - To try again\n",
    "3. **quit** - Go back to sleep mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"INSERT INTO trackingDetails_trackers (empId,is_active,lastUpdatedBy) VALUES (%s, %s,%s)\"\n",
    "val = (\"helldsssssssssssssssssssssso\",True,datetime.now())\n",
    "mycursor.execute(sql, val)\n",
    "mydb.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Link Database\n",
    "import mysql.connector\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"db4free.net\",\n",
    "  user=\"shibinthomas\",\n",
    "  password=\"shibint85@\",\n",
    "  database=\"shibinthomas\"\n",
    ")\n",
    "\n",
    "mycursor = mydb.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'John', datetime.datetime(2022, 4, 15, 21, 57, 24, 281786), 1)\n",
      "(2, 'John', datetime.datetime(2022, 4, 15, 22, 11, 6, 516091), 1)\n",
      "(3, 'John', datetime.datetime(2022, 4, 15, 22, 11, 29, 884335), 1)\n",
      "(4, 'John', datetime.datetime(2022, 4, 15, 22, 11, 51, 384052), 1)\n",
      "(5, 'hello', datetime.datetime(2022, 4, 15, 22, 11, 56, 962446), 1)\n",
      "(6, 'hello', datetime.datetime(2022, 4, 15, 22, 12, 12, 674127), 1)\n",
      "(7, 'hello', datetime.datetime(2022, 4, 15, 22, 12, 32, 147008), 1)\n",
      "(8, 'hello', datetime.datetime(2022, 4, 15, 22, 20, 47, 747382), 1)\n",
      "(9, 'hello', datetime.datetime(2022, 4, 15, 22, 35, 14, 472968), 1)\n",
      "(12, 'John', datetime.datetime(2022, 4, 15, 22, 48, 34, 119004), 1)\n",
      "(13, 'Johcccccccccccccccn', datetime.datetime(2022, 4, 15, 22, 48, 42, 680769), 1)\n",
      "(14, 'helldsssssssssssssssssssssso', datetime.datetime(2022, 4, 15, 22, 49, 15, 66616), 1)\n",
      "(15, 'Saktheeswaran', datetime.datetime(2022, 4, 15, 22, 50, 37, 672644), 1)\n",
      "(16, 'helldsssssssssssssssssssssso', datetime.datetime(2022, 4, 15, 22, 51, 32, 184117), 1)\n",
      "(17, 'Johcccccccccccccccn', datetime.datetime(2022, 4, 15, 22, 51, 40, 353082), 1)\n",
      "(18, 'Saktheeswaran', datetime.datetime(2022, 4, 15, 22, 58, 30, 486407), 1)\n",
      "(19, 'EMP0001', datetime.datetime(2022, 4, 15, 23, 3, 58, 881428), 1)\n",
      "(20, 'EMP0001', datetime.datetime(2022, 4, 16, 17, 46, 44, 999774), 1)\n",
      "(21, 'EMP2', datetime.datetime(2022, 4, 16, 19, 36, 45, 76172), 1)\n",
      "(22, 'EMP2', datetime.datetime(2022, 4, 16, 20, 30, 23, 611186), 1)\n"
     ]
    }
   ],
   "source": [
    "#Print Database\n",
    "mycursor.execute(\"SELECT * FROM trackingDetails_trackers\")\n",
    "\n",
    "myresult = mycursor.fetchall()\n",
    "\n",
    "for x in myresult:\n",
    "  print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected as: EMP1\n",
      "Listening... Recognizing...\n",
      "Recognized as:  yes\n",
      "4\n",
      "EMP1\n",
      "Thank You Next Person please\n",
      "Detected as: EMP1\n",
      "Listening... Recognizing...\n",
      "Recognized as:  yes\n",
      "5\n",
      "EMP1\n",
      "Thank You Next Person please\n"
     ]
    }
   ],
   "source": [
    "face_rec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Collecting beep\n",
      "\n",
      "  Downloading beep-2022.2.7.14-py3-none-any.whl (309 kB)\n",
      "Collecting msgpack-python==0.5.6\n",
      "  Downloading msgpack-python-0.5.6.tar.gz (138 kB)\n",
      "Collecting lmfit==1.0.3"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement scikit-learn==1.0.2 (from beep) (from versions: 0.9, 0.10, 0.11, 0.12, 0.12.1, 0.13, 0.13.1, 0.14, 0.14.1, 0.15.0b1, 0.15.0b2, 0.15.0, 0.15.1, 0.15.2, 0.16b1, 0.16.0, 0.16.1, 0.17b1, 0.17, 0.17.1, 0.18, 0.18.1, 0.18.2, 0.19b2, 0.19.0, 0.19.1, 0.19.2, 0.20rc1, 0.20.0, 0.20.1, 0.20.2, 0.20.3, 0.20.4, 0.21rc2, 0.21.0, 0.21.1, 0.21.2, 0.21.3, 0.22rc2.post1, 0.22rc3, 0.22, 0.22.1, 0.22.2, 0.22.2.post1, 0.23.0rc1, 0.23.0, 0.23.1, 0.23.2, 0.24.dev0, 0.24.0rc1, 0.24.0, 0.24.1, 0.24.2)\n",
      "ERROR: No matching distribution found for scikit-learn==1.0.2 (from beep)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading lmfit-1.0.3.tar.gz (292 kB)\n",
      "Collecting botocore==1.23.37\n",
      "  Downloading botocore-1.23.37-py3-none-any.whl (8.5 MB)\n",
      "Collecting click==8.0.3\n",
      "  Downloading click-8.0.3-py3-none-any.whl (97 kB)\n",
      "Collecting python-dateutil==2.8.2\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n"
     ]
    }
   ],
   "source": [
    "pip install beep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
